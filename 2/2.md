**1. Описание системы**

```python
def F(x):
    x1, x2 = x
    f1 = np.sinh(x1 + 0.2*x2 + np.tan(0.1*x1*x2)) - 0.8
    f2 = np.sinh(0.6*x1 - 0.1*x2 + np.tan(0.2*x1*x2)) - 0.1
    return np.array([f1, f2])
```

Функция `F` принимает вектор ((x_1,x_2)) и возвращает значения двух уравнений.
Система (F(x)=0) означает, что мы ищем такие ((x_1,x_2)), при которых оба выражения равны нулю.

---

**2. Построение функционала для минимизации**

```python
def Phi(x):
    f = F(x)
    return 0.5 * np.dot(f, f)
```

Функция `Phi` — скалярная, равная половине суммы квадратов компонентов `F(x)`.
Минимизация `Phi` эквивалентна решению системы (F(x)=0).

---

**3. Вычисление градиента (численно)**

```python
def grad_Phi(x, h=1e-6):
    g = np.zeros_like(x)
    for i in range(len(x)):
        dx = np.zeros_like(x)
        dx[i] = h
        g[i] = (Phi(x+dx) - Phi(x-dx)) / (2*h)
    return g
```

Градиент вычисляется методом центральных конечных разностей.
Элемент `g[i]` показывает частную производную по `x[i]`.

---

**4. Метод градиентного спуска**

```python
def gradient_descent(x0, alpha=0.01, eps=1e-4, max_iter=10000):
    x = np.array(x0, dtype=float)
    for k in range(max_iter):
        grad = grad_Phi(x)
        x_new = x - alpha * grad
        if np.linalg.norm(x_new - x) < eps:
            print(f"Итерация {k}")
            print(f"x = {x_new}")
            print(f"Phi(x) = {Phi(x_new)}")
            print(f"grad Phi(x) = {grad_Phi(x_new)}")
            print(f"Точность достигнута: {eps}")
            return x_new
        x = x_new
    print("Максимум итераций")
    return x
```

* `x0` — начальное приближение.
* `alpha` — шаг градиентного спуска.
* `eps` — критерий по изменению вектора между итерациями.
  На каждой итерации вычисляется градиент и выполняется шаг в противоположном направлении градиента.

---

**5. Проверка решения**

```python
x_sol = gradient_descent(x_start, alpha=0.01, eps=1e-4)
Fx = F(x_sol)
norm_F = np.linalg.norm(Fx)
Phi_val = Phi(x_sol)

print("\n--- Проверка решения ---")
print(f"x* = {x_sol}")
print(f"F(x*) = {Fx}")
print(f"||F(x*)|| = {norm_F}")
print(f"Phi(x*) = {Phi_val}")
if norm_F < 1e-3:
    print("Система удовлетворена с требуемой точностью.")
else:
    print("Остаток ещё заметен, можно уменьшить eps или шаг alpha.")
```

Проверяем норму `F(x*)`. Если она мала — система решена.
`Phi(x*)` также должно быть близко к нулю.

---

**Итог**:
Код ищет минимум функции `Phi(x)` методом градиентного спуска.
В точке минимума `F(x*)≈0`, градиент почти ноль, решение системы найдено.
Вывод включает значение `x*`, количество итераций, `Phi(x*)`, градиент и остаток системы.
