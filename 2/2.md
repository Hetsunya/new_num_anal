
# Метод градиентного спуска для решения системы F(x)=0

## 1. Описание системы

```python
def F(x):
    x1, x2 = x
    f1 = np.sinh(x1 + 0.2*x2 + np.tan(0.1*x1*x2)) - 0.8
    f2 = np.sinh(0.6*x1 - 0.1*x2 + np.tan(0.2*x1*x2)) - 0.1
    return np.array([f1, f2])
````

* `F(x)` принимает вектор ((x_1,x_2)) и возвращает значения двух уравнений.
* Система (F(x)=0) ищет такие ((x_1,x_2)), при которых оба выражения равны нулю.

---

## 2. Построение функционала для минимизации

```python
def Phi(x):
    f = F(x)
    return 0.5 * np.dot(f, f)
```

* `Phi(x)` — скалярная функция, равная половине суммы квадратов компонентов `F(x)`.
* Минимизация `Phi(x)` эквивалентна решению системы (F(x)=0).

---

## 3. Градиент Phi (численно)

```python
def grad_Phi(x, h=1e-6):
    g = np.zeros_like(x)
    for i in range(len(x)):
        dx = np.zeros_like(x)
        dx[i] = h
        g[i] = (Phi(x+dx) - Phi(x-dx)) / (2*h)
    return g
```

* Вычисляется методом центральных конечных разностей.
* `g[i]` — частная производная `Phi` по `x[i]`.

---

## 4. Метод градиентного спуска

```python
def gradient_descent(x0, alpha=0.1, eps=1e-6, max_iter=100000):
    x = np.array(x0, dtype=float)
    for k in range(max_iter):
        grad = grad_Phi(x)
        x_new = x - alpha * grad
        if np.linalg.norm(x_new - x) < eps:
            return x_new, k+1
        x = x_new
    raise RuntimeError("Метод не сошелся за максимум итераций")
```

* `x0` — начальное приближение.
* `alpha` — шаг градиентного спуска.
* `eps` — критерий выхода по изменению вектора.
* Функция возвращает найденное решение `x_new` и количество итераций.

---

## 5. Проверка решения

```python
solution, iterations = gradient_descent([0.0, 0.0], alpha=0.1, eps=1e-6)
Fx = F(solution)
norm_F = np.linalg.norm(Fx)
Phi_val = Phi(solution)

print(f"x* = {solution}")
print(f"F(x*) = {Fx}")
print(f"||F(x*)|| = {norm_F}")
print(f"Phi(x*) = {Phi_val}")
```

* Проверяем норму `F(x*)`. Если мала, система решена.
* `Phi(x*)` показывает близость к минимуму функционала.

---

## 6. Вывод результатов

* Формируем аккуратную таблицу через `pandas`:

```python
import pandas as pd

prec = 6
df = pd.DataFrame({
    "x1":[round(solution[0], prec)],
    "x2":[round(solution[1], prec)],
    "F1":[round(Fx[0], prec)],
    "F2":[round(Fx[1], prec)]
})
print(df)
```

* Проверка подстановкой:

```python
print(f"f1({solution[0]:.6f}, {solution[1]:.6f}) = {Fx[0]:.6e}, "
      f"f2({solution[0]:.6f}, {solution[1]:.6f}) = {Fx[1]:.6e}")
```

---

## Итог

* Код строит последовательность (x^{k+1} = x^k - \alpha \nabla \Phi(x^k)) до сходимости.
* В точке минимума `Phi(x*)` почти ноль, градиент почти ноль, система (F(x^*)\approx 0).
* Вывод включает:

  * найденное решение `x*`
  * количество итераций
  * значение `Phi(x*)`
  * градиент `grad Phi(x*)`
  * норму остатка `||F(x*)||`
  * таблицу и проверку подстановкой.
